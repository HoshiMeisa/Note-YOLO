# 1 Motivation

## 1.1 存在的问题

目前，有些检测器为了评估检测框的质量，会在detection head添加一个与分类分支和回归分支并行的新分支，比如FCOS/ATSS中的centerness分支、IoU-Net中的IoU score分支。通常这些表示预测框质量的分支的输出值是0~1内的连续值。

![image-20230701105725234](./.assets/image-20230701105725234.png)

- IoU-Net

![image-20230701110630533](./.assets/image-20230701110630533.png)

尽管新添加的预测框质量评估分值可以提高检测器的性能，但是也会存在两个问题

- **classification score和IoU/centerness score训练测试不一致**

![image-20230701110719404](./.assets/image-20230701110719404.png)

1） **用法不一致**。训练时，分类分支和质量估计分支是各自独立训练的，但测试时，却又是乘在一起作为NMS score排序的依据，这个操作显然没有end-to-end，必然存在一定的gap。

2） 对象不一致。借助Focal Loss的力量，分类分支能够使得少量的正样本和大量的负样本一起成功训练，但是质量估计通常就只针对正样本训练。那么，对于one-stage的检测器而言，在做NMS score排序的时候，所有的样本都会将分类score和质量预测score相乘用于排序，那么必然会存在一部分分数较低的“负样本”的质量预测是没有在训练过程中有监督信号的，有就是说对于大量可能的负样本，他们的质量预测是一个未定义行为。这就很有可能引发这么一个情况：一个分类score相对低的真正的负样本，由于预测了一个不可信的极高的质量score，而导致它可能排到一个真正的正样本（分类score不够高且质量score相对低）的前面，如图所示：
![image-20230701110832476](./.assets/image-20230701110832476.png)

- **bbox regression采用的表示不够灵活，没有办法建模复杂场景下的不确定性**

在复杂场景中，边界框的表示具有很强的不确定性，而现有的框回归本质都是建模了非常单一的狄拉克分布，非常不灵活。我们希望用一种更一般的分布去建模边界框的表示。如图所示（比如被水模糊掉的滑板，以及严重遮挡的大象）：

![image-20230701110903626](./.assets/image-20230701110903626.png)



## 1.2 本文的解决方法

对于第一个问题，为了保证训练和测试时的一致性，同时保证分类score和质量预测score都能够训练到所有的正负样本，将两者的表示进行联合，此时将分类分支和质量评估分支合在一起，得到的输出不再表示单一的类别score或质量预测score，而是两者的联合表示。

![image-20230701110956143](./.assets/image-20230701110956143.png)